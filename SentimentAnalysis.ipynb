{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "919521a4",
   "metadata": {},
   "source": [
    "# Proyecto de análisis de sentimientos con Python\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae3550be",
   "metadata": {},
   "source": [
    "Curso 2022/2023\n",
    "    Juan López Quirós\n",
    "    Jose Castro Vázquez"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25ad663c",
   "metadata": {},
   "source": [
    " Lo primero que hay que hacer es escoger o recopilar una primera versión de los datos necesarios que utilizarmos \n",
    " para entrenar a nuestros modelos de Aprendizaje automático. \n",
    " Tras haber estudiado los varios problemas con la API de twitter y las alternativas propuestas, nos decidimos por \n",
    " buscar un dataset ya recopilado de tweets reales de la página web kaggle. En concreto nos decidimos por un dataset\n",
    " ya enfocado al análisis de sentimientos con más de 1.6 millones de tweets recopilados directamente de la API de twitter\n",
    " por lo que se ajusta perfectamente al proyecto.\n",
    "\n",
    " url : https://www.kaggle.com/datasets/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "raw",
   "id": "811715a9",
   "metadata": {},
   "source": [
    " Luego, tenemos que limpiar el dataset escogido para este proyecto.\n",
    " A nosotros solo nos interesa una columna en particular de todo el dataset y ese es la columna de texto, que contiene\n",
    " el contenido de los tweets en sí. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86fe3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_cleaned_csv(original_filename, target_filename):\n",
    "    data = pd.read_csv(original_filename, encoding=\"latin1\", header=None)\n",
    "    print(\"ORIGINAL: \\n\")\n",
    "    print(data[25:30])\n",
    "\n",
    "    #We give the columns a name\n",
    "    column_names = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "    data.columns = column_names\n",
    "    print(\"GIVE COLUMN NAMES: \\n\")\n",
    "    print(data[25:30])\n",
    "\n",
    "    #We eliminate innecessary columns\n",
    "    data.drop(columns=[\"target\", \"id\", \"date\", \"flag\", \"user\"], inplace=True)\n",
    "\n",
    "    #We put the cleaned data into a new csv file\n",
    "    data_cleaned = target_filename\n",
    "    data.to_csv(data_cleaned, index=False)\n",
    "    print(\"FINAL RESULT: \\n\")\n",
    "    print(data[25:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e3af96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL: \n",
      "\n",
      "    0           1                             2         3                4  \\\n",
      "25  0  1467814438  Mon Apr 06 22:20:44 PDT 2009  NO_QUERY    ChicagoCubbie   \n",
      "26  0  1467814783  Mon Apr 06 22:20:50 PDT 2009  NO_QUERY      KatieAngell   \n",
      "27  0  1467814883  Mon Apr 06 22:20:52 PDT 2009  NO_QUERY            gagoo   \n",
      "28  0  1467815199  Mon Apr 06 22:20:56 PDT 2009  NO_QUERY          abel209   \n",
      "29  0  1467815753  Mon Apr 06 22:21:04 PDT 2009  NO_QUERY  BaptisteTheFool   \n",
      "\n",
      "                                                    5  \n",
      "25     I hate when I have to call and wake people up   \n",
      "26  Just going to cry myself to sleep after watchi...  \n",
      "27                             im sad now  Miss.Lilly  \n",
      "28  ooooh.... LOL  that leslie.... and ok I won't ...  \n",
      "29  Meh... Almost Lover is the exception... this t...  \n",
      "GIVE COLUMN NAMES: \n",
      "\n",
      "    target          id                          date      flag  \\\n",
      "25       0  1467814438  Mon Apr 06 22:20:44 PDT 2009  NO_QUERY   \n",
      "26       0  1467814783  Mon Apr 06 22:20:50 PDT 2009  NO_QUERY   \n",
      "27       0  1467814883  Mon Apr 06 22:20:52 PDT 2009  NO_QUERY   \n",
      "28       0  1467815199  Mon Apr 06 22:20:56 PDT 2009  NO_QUERY   \n",
      "29       0  1467815753  Mon Apr 06 22:21:04 PDT 2009  NO_QUERY   \n",
      "\n",
      "               user                                               text  \n",
      "25    ChicagoCubbie     I hate when I have to call and wake people up   \n",
      "26      KatieAngell  Just going to cry myself to sleep after watchi...  \n",
      "27            gagoo                             im sad now  Miss.Lilly  \n",
      "28          abel209  ooooh.... LOL  that leslie.... and ok I won't ...  \n",
      "29  BaptisteTheFool  Meh... Almost Lover is the exception... this t...  \n",
      "FINAL RESULT: \n",
      "\n",
      "                                                 text\n",
      "25     I hate when I have to call and wake people up \n",
      "26  Just going to cry myself to sleep after watchi...\n",
      "27                             im sad now  Miss.Lilly\n",
      "28  ooooh.... LOL  that leslie.... and ok I won't ...\n",
      "29  Meh... Almost Lover is the exception... this t...\n"
     ]
    }
   ],
   "source": [
    "create_cleaned_csv(\"tweet_data.csv\", \"tweet_cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5700f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
